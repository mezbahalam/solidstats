module Solidstats
  class <%= class_name %>Service
    CACHE_KEY = "solidstats_<%= file_name %>".freeze
    CACHE_HOURS = <%= options[:cache_hours] %>

    def initialize
      @cache_file = Rails.root.join("tmp", "#{CACHE_KEY}.json")
    end

    # Fetch cached data or collect fresh data
    def fetch(force_refresh = false)
      if force_refresh || cache_expired?
        data = collect_data
        cache_data(data)
        data
      else
        cached_data
      end
    end

    # Get summary data for dashboard cards
    def summary
      data = fetch
      {
        value: calculate_summary_value(data),
        status: determine_status(data),
        last_updated: data[:last_updated] || Time.current,
        count: data[:count] || 0
      }
    end

    # Collect detailed data for full view
    def detailed_data
      fetch.merge(
        breakdown: calculate_breakdown(fetch),
        trends: calculate_trends(fetch)
      )
    end

    private

    def collect_data
      # TODO: Implement your data collection logic here
      # This is where you'd gather metrics, run system commands, 
      # analyze files, or call external APIs
      
      {
        value: sample_value,
        count: sample_count,
        items: sample_items,
        last_updated: Time.current,
        status: :ok
      }
    rescue StandardError => e
      Rails.logger.error "Error collecting <%= file_name %> data: #{e.message}"
      {
        value: 0,
        count: 0,
        items: [],
        last_updated: Time.current,
        status: :error,
        error: e.message
      }
    end

    def calculate_summary_value(data)
      # TODO: Customize how the main metric is calculated
      data[:value] || 0
    end

    def determine_status(data)
      # TODO: Implement your status logic
      # Return :ok, :warning, or :danger based on your metrics
      
      return :error if data[:error]
      return :ok if data[:value].to_i < 50
      return :warning if data[:value].to_i < 100
      :danger
    end

    def calculate_breakdown(data)
      # TODO: Implement breakdown analysis for detailed view
      data[:items]&.group_by { |item| item[:category] } || {}
    end

    def calculate_trends(data)
      # TODO: Implement trend analysis
      # This could compare with historical data
      []
    end

    # Sample data methods - replace with your actual logic
    def sample_value
      rand(1..100)
    end

    def sample_count
      rand(1..20)
    end

    def sample_items
      (1..sample_count).map do |i|
        {
          name: "Item #{i}",
          value: rand(1..10),
          category: ["category_a", "category_b", "category_c"].sample,
          created_at: Time.current - rand(24).hours
        }
      end
    end

    # Cache management
    def cache_expired?
      return true unless @cache_file.exist?
      
      File.mtime(@cache_file) < CACHE_HOURS.hours.ago
    end

    def cached_data
      return {} unless @cache_file.exist?
      
      JSON.parse(File.read(@cache_file)).deep_symbolize_keys
    rescue JSON::ParserError
      {}
    end

    def cache_data(data)
      FileUtils.mkdir_p(@cache_file.dirname)
      File.write(@cache_file, data.to_json)
    end
  end
end
